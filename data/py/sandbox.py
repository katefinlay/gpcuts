#%% Importsimport osimport jsonimport numpy as npimport pandas as pdfrom datetime import datetime#%% General Practice / Individual level datasets# Note - you'll have to download these folders and store under ./data/csv/practice_2022 = pd.read_csv('./data/csv/GPWPracticeCSV.092022/37. General Practice – September 2022 Practice Level.csv')indiv = pd.read_csv('./data/csv/GPWIndividualCSV.092022/37. General Practice – September 2022 Individual Level.csv', nrows=100)defs_practice = pd.read_excel(f'./data/csv/GPWPracticeCSV.092022/General Practice Practice-Level CSV. Overall Definitions.xlsx')defs_indiv = pd.read_excel(f'./data/csv/GPWIndividualCSV.092022/General Practice Individual-Level CSV. Overall Definitions.xlsx')practice_2013 = pd.read_csv('./data/csv/General Practice 2013 Practice Level.csv')#%% Practice locationslocation_columns = [    'Organisation Code',    'Name',    'National Grouping',    'High Level Health Geography',    'Address Line 1',    'Address Line 2',    'Address Line 3',    'Address Line 4',    'Address Line 5',    'Postcode',    'Open Date',    'Close Date',    'Status Code',    'Organisation Sub-Type Code',    'Commissioner',    'Join Provider/Purchaser Date',    'Left Provider/Purchaser Date',    'Contact Telephone Number',    'Amended Record Indicator',    'Provider/Purchaser',    'Prescribing Setting']usecols = list(range(0, 18)) + [21, 23, 25]practice_locations = pd.read_csv('./data/gplocations/epraccur.csv', usecols = usecols, names=location_columns)practice_locations['postcode_merge_col'] = practice_locations['Postcode'].str.lower().str.replace(' ','').str.strip()#%%postcodes = pd.read_csv('./data/csv/postcodes/postcodes.csv')postcodes['postcode_merge_col'] = postcodes['Postcode'].str.lower().str.replace(' ','').str.strip()#%%# Assign latitude & longitude, and Parliamentary Constituency to practice locationsconstituencies = pd.read_csv('./data/csv/parliamentary_constituencies/UK Constituency Postcodes.csv')#%%merged = practice_locations.merge(postcodes[['postcode_merge_col','Latitude','Longitude','Constituency Code']], how='left', on='postcode_merge_col')merged = merged.merge(constituencies[['Code', 'MP', 'Party', 'Constituency']], right_on='Code', left_on='Constituency Code', how='left')for col in ['Address Line 1', 'Address Line 2', 'Address Line 3', 'Address Line 4', 'Address Line 5']:    merged[col] = merged[col].fillna('')#%%x = practice_locations[~practice_locations['Organisation Code'].isin(practice['PRAC_CODE'].values)]x.to_csv('./data/csv/practice_locations_not_found_in_snapshot.csv', index=False)#%%def parse_date(date):    try:        datetime.strptime(int(date), '%Y%m%d').strftime('%Y-%m-%d')    except:        return Nonegeojson = {"type": "FeatureCollection", "features": []}leeds = merged[merged['postcode_merge_col'].str[:2] == 'ls']for _, row in leeds.iterrows():    feature = {        "type": "Feature",         "geometry": {            "type": "Point",             "coordinates": [                row['Longitude'],                 row['Latitude']]            },         "properties": {            "organisation_code": row["Organisation Code"],            "name": row['Name'],            "address_line_1": row["Address Line 1"],            "address_line_2": row["Address Line 2"],            "address_line_3": row["Address Line 3"],            "address_line_4": row["Address Line 4"],            "address_line_5": row["Address Line 5"],            "postcode": row["Postcode"],            "open_date": parse_date(row["Open Date"]),            "close_date": parse_date(row["Close Date"]),            "status_code": row["Status Code"],            "constituency_code": row["Constituency Code"],            "Consituitency": row["Constituency"],            "MP": row["MP"],            "Party": row["Party"],                        }        }    geojson['features'].append(feature)with open('./data/json/practices.geojson', 'w') as fp:    json.dump(geojson, fp)#%% SET ANALYSISimport pylab as pltfrom matplotlib_venn import venn3, venn3_circlesdef generate_venn(practices_global, drop_global_closures=False):    if drop_global_closures:        practices_global = practices_global[practices_global['Status Code'] == 'C']    practice_2013_codes = set(practice_2013['PRAC_CODE'].drop_duplicates().tolist())    practice_2022_codes = set(practice_2022['PRAC_CODE'].drop_duplicates().tolist())    practices_global = set(practices_global['Organisation Code'].drop_duplicates().tolist())        # Use the venn2 function    v = venn3(        subsets = (            len(practice_2013_codes.difference(practice_2022_codes).difference(practices_global)),             len(practice_2022_codes.difference(practice_2013_codes).difference(practices_global)),            len(practice_2013_codes.intersection(practice_2022_codes).difference(practices_global)),             len(practices_global.difference(practice_2022_codes).difference(practice_2013_codes)),             len(practice_2013_codes.intersection(practices_global).difference(practice_2022_codes)),             len(practice_2022_codes.intersection(practices_global).difference(practice_2013_codes)),             len(practice_2022_codes.intersection(practices_global).intersection(practice_2013_codes))        ),         set_labels = ('Practices 2013', 'Practices 2022', 'Practices Global'),         set_colors=('purple', 'skyblue', 'red'),         alpha = 0.4    )        if drop_global_closures:        plt.title("Practices in 2013 vs in 2022, plus global dataset (excluding closures in global dataset)")    else:        plt.title("Practices in 2013 vs in 2022, plus global dataset")            plt.show()generate_venn(practice_locations, drop_global_closures=False)generate_venn(practice_locations, drop_global_closures=True)#%%missing = practices_global.difference(practice_2022_codes).difference(practice_2013_codes)practice_locations = practice_locations[practice_locations['Organisation Code'].isin(list(missing))]#%%